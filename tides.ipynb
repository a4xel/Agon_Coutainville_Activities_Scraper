{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tide data scraper\n",
    "\n",
    "This notebook scrapes data from https://marine.meteoconsult.fr/meteo-marine/horaires-des-marees/pointe-d-agon-944/juillet-2022\n",
    "to retrieve information about the tides dates, coefficients and times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"Do the necessary imports\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Scrape a first time to all the months where data about the tides can be found and create a list that \n",
    "can be pluged in the url to load all the pages where scrapable data is available\"\"\"\n",
    "\n",
    "url = \"https://marine.meteoconsult.fr/meteo-marine/horaires-des-marees/pointe-d-agon-944/juillet-2022\"\n",
    "\n",
    "response=requests.get(url)\n",
    "\n",
    "soup1 = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "list_dates=[]\n",
    "list_years=[]\n",
    "\n",
    "for i in soup1.find_all(class_=\"month-container\"):\n",
    "    list_dates.append((i.find(class_=\"name\").text))\n",
    "    list_years.append((i.find(class_=\"year\").text))\n",
    "    \n",
    "list_dates_and_years = [m+str(n) for m,n in zip(list_dates, list_years)]\n",
    "\n",
    "month_years_final=[]\n",
    "for i in list_dates_and_years:\n",
    "    i=i.replace(\"20\", \"-20\")\n",
    "    month_years_final.append(i)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code iterates over each of the periods for which data is available on the website\n",
    "For each period, the corresponding web page is scrapped and data about the date (two classes scrapped because\n",
    "of the distinction between weekends days and week days made on the website), the time of the low and high tides,\n",
    "the value of the coefficient of the first and second ties.\n",
    "Once this data is collected, it is reshaped to eliminate the \\n obtained with the scraped information.\n",
    "The times are also formated so that a distinction is made between the time of each tide (4 tides per day in total)\n",
    "Finally all the data is grouped in a dataframe which is then saved as a csv (one dataframe per month)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Loop on each month and extract the information\"\"\"\n",
    "\n",
    "url = \"https://marine.meteoconsult.fr/meteo-marine/horaires-des-marees/pointe-d-agon-944\"\n",
    "\n",
    "\n",
    "for month in month_years_final:\n",
    "    \n",
    "    days=[]\n",
    "    high_tide_time=[]\n",
    "    low_tide_time=[]\n",
    "    first_tide_coeff=[]\n",
    "    second_tide_coeff=[]\n",
    "      \n",
    "    req=requests.get(url + f\"/{month}\")\n",
    "    soup = BeautifulSoup(req.content, 'html.parser')\n",
    "    \n",
    "    for i in soup.find_all(class_= [\"tide-date week\", \"tide-date weekEnd\"]):\n",
    "        days.append(i.text)\n",
    "\n",
    "    for i in soup.find_all(class_=\"high-tide\"):\n",
    "        high_tide_time.append(i.find(class_=\"hour\").text)\n",
    "\n",
    "    for i in soup.find_all(class_=\"low-tide\"):\n",
    "        low_tide_time.append(i.find(class_=\"hour\").text)\n",
    "\n",
    "    for index,value in enumerate(soup.find_all(class_=[\"coef tide-coef-level-1\",\"coef tide-coef-level-2\",\"coef tide-coef-level-3\",\"coef tide-coef-level-4\",\"coef tide-coef-level-5\"])):\n",
    "        if (index%2) == 0:\n",
    "            first_tide_coeff.append(value.text)\n",
    "        else:\n",
    "            second_tide_coeff.append(value.text)\n",
    "            \n",
    "    \"\"\"Do the necessary reshapes\"\"\"\n",
    "    \n",
    "    days_formated=[]\n",
    "    for i in days:\n",
    "        i=i.replace(\"\\n\",\"\")\n",
    "        days_formated.append(i)\n",
    "\n",
    "    first_tide_coeff_formated=[]\n",
    "    for i in first_tide_coeff:\n",
    "        i=i.replace(\"\\n\",\"\")\n",
    "        first_tide_coeff_formated.append(i)\n",
    "\n",
    "    second_tide_coeff_formated=[]\n",
    "    for i in second_tide_coeff:\n",
    "        i=i.replace(\"\\n\",\"\")\n",
    "        second_tide_coeff_formated.append(i)\n",
    "        \n",
    "    high_tide_time_1=[]\n",
    "    high_tide_time_2=[]\n",
    "    low_tide_time_1=[]\n",
    "    low_tide_time_2=[]\n",
    "\n",
    "    for index, value in enumerate(high_tide_time):\n",
    "        if index%2==0:\n",
    "            high_tide_time_1.append(value)\n",
    "        else:\n",
    "            high_tide_time_2.append(value)\n",
    "            \n",
    "    for index, value in enumerate(low_tide_time):\n",
    "        if index%2==0:\n",
    "            low_tide_time_1.append(value)\n",
    "        else:\n",
    "            low_tide_time_2.append(value)\n",
    "            \n",
    "    \"\"\"Zip the different lists in a unique data set\"\"\"\n",
    "            \n",
    "    result = zip(days_formated,first_tide_coeff_formated,second_tide_coeff_formated,high_tide_time_1,high_tide_time_2,low_tide_time_1,low_tide_time_2)\n",
    "    tide_calendar = pd.DataFrame(list(result), columns = ['Date', \"Coeff1\",'Coeff2',\"first_high_tide\",\"second_high_tide\",\"first_low_tide\",\"second_low_tide\"])\n",
    "     \n",
    "    \n",
    "    \"\"\"For each loop save the data set of the corresponding month\"\"\"        \n",
    "    file_path = os.getcwd()\n",
    "\n",
    "    tide_calendar.to_csv(file_path+f\"/results_tides/{month}.csv\")\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunatly some of the dataframes will be incorrect due to the fact that some days have less than 4 tides per day, which\n",
    "results in the creation of a gap in the data. This only happens very infrequently and can therefore be corrected by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('shims')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b23a059732edb4bfbb23e8cd4fc458f3edfb684a0d6eec5d0f4069a80889721"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
